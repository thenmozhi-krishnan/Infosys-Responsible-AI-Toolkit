# Responsible-AI-Hallucination

## Table of Contents

- [Introduction](#introduction)
- [Features](#features)
- [Installation](#installation)
- [Set Configuration Variables](#set-configuration-variables)
- [Running the Application](#running-the-application)
- [License](#license)
- [Contact](#contact)

## Introduction

Hallucination in LLMs refers to the generation of text or predictions that deviate from factual accuracy, instead reflecting the model's internal biases, noise, or overgeneralization. This phenomenon occurs when an LLM's complex patterns and associations learned during training overshadow its ability to discern reality, leading to fabricated, inaccurate, or nonsensical outputs. 

## Features
- **Document RAG** 
    Extract and cross-check information from documents to enhance response accuracy and minimize hallucinations.
- **Multi-modal RAG** 
    Image Retrieval RAG (Retrieval Augmented Generation) is an advanced AI-based technology that enhances the capabilities of Responsible AI by incorporating multimodal inputs. It not only processes text inputs but also analyzes images, providing a more comprehensive and context-aware response.
- **Hallucination score**
    Quantify the probability of a response containing fabricated or inaccurate information.
- **G-Eval**
    The G-eval metrics are tools used to evaluate the performance and quality of texts generated by LLMs, taking into account the many specific nuances of these models. The G-Eval metrics leverage existing AI models and evaluate metrics like relevance, adherence, correctness, and faithfulness to assess the response generated by the LLM. 
- **Chain of Thoughts**
    CoT refers to a structured approach in problem-solving, where complex tasks are broken down into a sequence of logical steps.
- **Thread of Thoughts**
    Address challenges in chaotic contexts, where LLMs struggle to sift through and prioritize relevant information amidst a plethora of data.
- **Chain of Verification**
    This measure is implemented directly to counteract hallucinations. As a reminder, hallucinations occur when the LLM responds incorrectly but in a logically coherent manner to a prompt.

## Pre-requisite 
Install the file storage respository by adding all the necessary required environment variables.

## Installation
To run the application, first we need to install Python and the necessary packages:

1. Install Python (version >= 3.9) from the [official website](https://www.python.org/downloads/) and ensure it is added to your system PATH.

2. Clone the repository:
    ```sh
    git clone <repository-url>
    ```

3. Navigate to the `RAG` directory:
    ```sh
    cd RAG
    ```

4. Create a virtual environment:
    ```sh
    python -m venv venv
    ```

5. Activate the virtual environment:
    - On Windows:
        ```sh
        .\venv\Scripts\activate
         ```

6. Go to the `requirements` directory where the `requirement.txt` file is present and install the requirements:
    ```sh
    pip install -r requirement.txt
    ```
7. Install moviepy==1.0.3:
   ```sh
    pip install moviepy==1.0.3
    ```

8. Download the following open source model: ["nreimers/MiniLM-L6-H384-uncased"] (https://huggingface.co/nreimers/MiniLM-L6-H384-uncased).

9. Replace the relative path for the similarity_model variable in the `service.py` file with the model's path.
    
10. For external environment please use the same similarity model as your embedding model. Comment line number 67 and uncomment line number 66 in the `service.py` file. Paste the path for the similarity_model folder in the "model_name" section of embedding model.

## Set Configuration Variables

After installing all the required packages, configure the variables necessary to run the APIs.

1. Navigate to the `src` directory:
    ```sh
    cd ..
    cd src
    ```

2. Locate the `.env` file, which contains keys like the following:

    ```sh
    DB_TYPE= "${dbtype}"
    OPENAI_MODEL = "${openaimodel}"
    OPENAI_API_TYPE = "${apitype}"
    OPENAI_API_BASE = "${apibase}"
    OPENAI_API_KEY = "${apikey}"
    OPENAI_API_VERSION = "${apiversion}"
    OPENAI_API_BASE_GPT4_O = "${api_base_o}"
    OPENAI_API_KEY_GPT4_O = "${api_key_o}"
    OPENAI_API_VERSION_GPT4_O = "${api_version_o}"  
    OPENAI_MODEL_GPT4_O = "${model_o}"
    AZUREADDFILE = "${azureaddfile}" # get this after cloning the file storage repo
    CONTAINERNAME = "${containername}"
    COLLECTIONNAME = "${collectionname}"
    AZUREBLOBNAME = "${azureBlobname}" #get this after cloning the file storage repo 
    SIMILARITYMODEL="${similaritymodel}"
    DB_NAME="${dbname}"
    DEFAULT_DB_NAME="${defaultdbname}"
    DB_USERNAME="${username}"
    DB_PWD="${password}"
    DB_IP="${ipaddress}"
    DB_PORT="${port}"
    MONGO_PATH="mongodb://${DB_USERNAME}:${DB_PWD}@${DB_IP}:${DB_PORT}/"
    COSMOS_PATH = "${cosmos_path}"
    ```
    Example Values
    ```sh
    # Database Configuration
    DB_TYPE="mongo"
    DB_NAME="rai_database"
    DEFAULT_DB_NAME="default_database"
    DB_USERNAME="user"
    DB_PWD="password123"
    DB_IP="127.0.0.1"
    DB_PORT="27017"
    MONGO_PATH="your_mongo_path"
    COSMOS_PATH="your_cosmos_path"

    # OpenAI Configuration
    OPENAI_MODEL="text-davinci-003"
    OPENAI_API_TYPE="openai"
    OPENAI_API_BASE="https://api.openai.com/v1"
    OPENAI_API_KEY="your_openai_api_key"
    OPENAI_API_VERSION="v1"

    # OpenAI GPT-4o Configuration
    OPENAI_API_BASE_GPT4_O="https://api.openai.com/v1"
    OPENAI_API_KEY_GPT4_O="your_openai_api_key_gpt4_o"
    OPENAI_API_VERSION_GPT4_O="v1"
    OPENAI_MODEL_GPT4_O="gpt-4o"

    # Cosmos Configuration
    CONTAINERNAME="your_cosmos_container_name"
    COLLECTIONNAME="your_cosmos_collection_name"
    AZUREADDFILE = `"your API link of azure addblob/api/v1/azureBlob/addFile"`
    AZUREBLOBNAME = `"your API link of azure getblob/api/v1/azureBlob/getBlob?"`
    
    ```
3. Replace the placeholders with your actual values.

## Running the Application

Once we have completed all the aforementioned steps, we can start the service.

1. Navigate to the `src` directory

2. Run `main.py` file:
    ```sh
    python main.py
    ```

3. Open the following port in your browser: `http://localhost:[PORT_NUMBER]/rag/v1/docs`

For API calls, please refer to the [API Document](Rag/docs/RAG_endpoints_Instruction.pdf)

## License

The source code for the project is licensed under MIT license, which you can find in the [LICENSE.md](LICENSE.md) file.

## Contact

If you have more questions or need further insights, feel free to Connect with us @ infosysraitoolkit@infosys.com
