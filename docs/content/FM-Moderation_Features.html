<!DOCTYPE html>
<html><head></head><body><div class="main-panel wiki-content">
<div class="description">
<div class="header-wrapper" style="max-width: initial">
<!-- breadcrumbs could be implemented and inserted here -->
<div></div>

</div>
<div class="header-wrapper">
<div class="title-wrapper">
<div class="title">
<h1 style="display: flex; align-items: center;">
                                        Moderation Layer - Features
                                    </h1>
</div>
<div class="row" style="display: flex;padding: 0; ">

</div>
</div>
</div>
<div class="content-wrapper">
<style>@media (prefers-color-scheme: dark) { }</style>
<div class="toc-macro client-side-toc-macro conf-macro output-block" data-cssliststyle="default" data-hasbody="false" data-headerelements="H1,H2,H3" data-layout="default" data-local-id="c8a7a098-8620-4996-93a8-fd1250e36f0a" data-macro-id="f107ddcf-c09d-466e-9ebb-a44f1ba151b7" data-macro-name="toc" data-numberedoutline="false" data-structure="list">
<ul>
<li><a class="not-blank" href="#ComponentsofInput">Components of Input</a>
<ul>
<li><a class="not-blank" href="#PromptandTemperatureParameters">Prompt and Temperature Parameters</a></li>
<li><a class="not-blank" href="#MultiLingualSupport">Multi-Lingual Support</a></li>
<li><a class="not-blank" href="#EmojiModeration">Emoji Moderation</a></li>
<li><a class="not-blank" href="#PromptTemplate">Prompt Template</a></li>
</ul></li>
<li><a class="not-blank" href="#ComponentsofOutput">Components of Output</a>
<ul>
<li><a class="not-blank" href="#Templatebasedguardrails">Template-based guardrails</a></li>
<li><a class="not-blank" href="#Modelbasedguardrails">Model-based guardrails</a></li>
</ul></li>
</ul>
</div>
<h2 id="ComponentsofInput">Components of Input<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h2>
<h3 id="PromptandTemperatureParameters">Prompt and Temperature Parameters<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h3>
<p>The FM Moderation module requires two input parameters: Prompt and Temperature. The Prompt is the first text provided to the model to generate a response, while the Temperature parameter controls the creativity of the response. A lower temperature value produces more precise and deterministic outputs, while a higher value introduces more creative elements into the response.</p>
<h3 id="MultiLingualSupport">Multi-Lingual Support<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h3>
<p>Multilingual support in FM (content) moderation entails the ability to process prompts and content in various languages. When a prompt is provided in any language, the system automatically detects the language and translates it to English for further processing. This functionality allows users to select options such as Google, Azure, or none, while ensuring seamless backend operations with language detection and translation mechanisms in place. This approach enables efficient and effective moderation across different languages, using automated processes to manage content consistently and accurately.</p>
<h3 id="EmojiModeration">Emoji Moderation<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h3>
<p>In FM moderation, emoji support allows users to include emojis to convey sentiments or expressions within sentences. By selecting the "emoji" option and specifying "yes," users show the presence of emojis in their input. Behind the scenes, the system detects these emojis and seamlessly integrates them into the moderation process. This functionality ensures that emojis are recognized and interpreted as part of the input, enabling the moderation system to effectively consider them when generating results or making decisions. This capability significantly enhances the system's ability to understand and respond to content having emojis, thereby improving the accuracy and relevance of moderation outcomes. </p>
<h3 id="PromptTemplate">Prompt Template<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h3>
<h4 id="GoalPriority">Goal Priority<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>Goal Priority is nothing but LLM checking involves assessing an LLM prompt for potential harmless and helpful. Importantly, you need to always prioritize safety over helpfulness. That is, if answering the user query could be unsafe or harmful, LLM refuses to answer. Otherwise provides a thorough and precise response, ensuring clarity, specificity, avoiding harmful stereotypes or discriminatory language. By conducting a smooth LLM check, developers can mitigate risks of generating harmful or misleading content, enhancing the overall quality and safety of the LLM's responses.</p>
<h4 id="SelfRemainder">Self-Remainder<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>Self Remainder is Nothing but A Bergeron check in the context of LLM prompts is a safety measure designed to prevent jailbreaking, or malicious manipulation, of the model. It involves analyzing the prompt for patterns or keywords associated with harmful or unintended behaviors. This can include detecting prompts that request harmful content, promote violence, or try to exploit vulnerabilities in the model. By showing and mitigating these prompts, Bergeron checks help ensure the LLM operates safely and ethically.</p>
<h4 id="CoveComplexity">Cove Complexity<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>Cove Complexity can be considered a synonymous term for The Cain of Verification. It is a rigorous evaluation method for LLMs that subjects generated responses to a series of increasingly complex logical questions. By tailoring the query difficulty to the selected level (simple, medium, or complex), this process effectively probes the LLM's ability to provide right, consistent, and logically sound information. Essentially, it acts as a quality control checkpoint, identifying potential weaknesses in the model's reasoning capabilities and factual knowledge.</p>
<h4 id="LLMModel">LLM Model<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>LLM explainability is still a significant challenge for both GPT-3 and GPT-4. While GPT-4 generally demonstrates improved performance, understanding the internal decision-making processes of these models is still limited. Both models use as black boxes, making it difficult to pinpoint the exact reasoning behind their outputs. Researchers and engineers are actively exploring techniques like attention visualizations and model introspection to shed light on these complex systems, but a comprehensive understanding of LLM explainability is yet to be achieved.</p>
<h2 id="ComponentsofOutput">Components of Output<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h2>
<p>In FM moderation, two types of outputs are distinguished: template-based guardrails and model-based guardrails.</p>
<h3 id="Templatebasedguardrails">Template-based guardrails<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h3>
<p>Where we make use of dynamic and efficient prompt templates through Prompt Engineering that enhance the detection capability of the llms to detect and block the adversarial attacks.</p>
<h4 id="RequestModeration">Request Moderation  <a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>In the Request Moderation layer, various checks are performed on the input prompt before generating a response. These checks include Prompt Injection, Jailbreak, Fairness and Bias, language critique coherence, language critique fluency, language critique grammar, language critique politeness, evaluator check, context relevance, context conciseness and context reranking. These checks ensure that the input prompt adheres to the defined guidelines and standards.</p>
<h5 id="PromptInjectionCheck">Prompt Injection Check<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>This check evaluates the presence of injected content in the input prompt. It calculates an injection confidence score based on the prompt and compares it against a dynamic injection threshold. The result writes down whether the check passes or fails.</p>
<h5 id="JailbreakCheck">Jailbreak Check<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>The Jailbreak check examines the input prompt for potential attempts to manipulate or bypass the moderation system. It calculates a jailbreak similarity score and compares it against a dynamic jailbreak threshold. The result says whether the check passes or fails.</p>
<h5 id="FairnessandBias">Fairness and Bias<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>In the context of request moderation, fairness and bias analysis aims to show potential discriminatory patterns or biases in the system's responses. This analysis typically examines various aspects of the moderation process.</p>
<h5 id="LanguageCritiqueCoherence">Language Critique Coherence<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>An evaluation of the logical connection and consistency between distinct parts of an explanation. It figures out how well the ideas are organized and linked together to form a cohesive narrative.</p>
<h5 id="LanguageCritiqueFluency">Language Critique Fluency<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>A measure of the smoothness and naturalness of the language used in an explanation. It assesses the flow of ideas and the overall readability of the text.</p>
<h5 id="LanguageCritiqueGrammar">Language Critique Grammar<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>An assessment of the grammatical correctness and adherence to language conventions in an explanation. It evaluates the syntax, punctuation, and overall linguistic accuracy of the text.</p>
<h5 id="LanguageCritiquePoliteness">Language Critique Politeness<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>A measure of the appropriateness and respectfulness of the language used in an explanation. It assesses the tone and choice of words to figure out if the explanation is polite and considerate of the audience.</p>
<h5 id="EvaluatorCheck">Evaluator Check<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>Before delving into the output, it's essential to understand the concept. Elevator check request moderation typically refers to a process where given requests for elevator inspections, repairs, or maintenance are reviewed and approved or rejected based on certain criteria.</p>
<h5 id="InfosysAdvancedJailbreakCheck">Infosys Advanced Jailbreak Check<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>Assuming "elevator check" is a misnomer or typo, and the actual focus is on security, Infosys Advanced Jailbreak Check likely refers to a system that assesses devices or systems for vulnerabilities that could potentially allow unauthorized access or control. This might involve checking for compromised software, weak passwords, or other security risks.</p>
<h5 id="InfosysRandomNoiseCheck">Infosys Random Noise Check<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>This could refer to a quality control or maintenance procedure where random elevators are checked for unusual noises. The output might include a list of elevators checked, the nature of the noise (if any), and the corresponding actions taken (e.g., maintenance scheduled).</p>
<h5 id="ContextRelevance">Context Relevance<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>Evaluates how relevant the retrieved context is to the question specified. Context relevance score measures if the retrieved context has enough information to answer the question being asked. This check is important since a bad context reduces the chances of the model giving a relevant response to the question asked, as well as leads to hallucinations.</p>
<h5 id="ContextConciseness">Context Conciseness<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>Evaluates the concise context cited from an original context for irrelevant information. Context conciseness refers to the quality of a reference context generated from retrieved context in terms of being clear, brief, and to the point. A concise context effectively conveys the necessary information without unnecessary elaboration or verbosity.</p>
<h5 id="ContextReranking">Context Reranking<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>Evaluates how efficient the reranked context is compared to the original context. Context Reranking reflects the efficiency of the reranking process applied to the original context in generating the new renamed context used to answer a given question. This operator assesses the degree to which the reranked context enhances the relevance, coherence, and informativeness with respect to the provided question.</p>
<h4 id="ResponseModeration">Response Moderation<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>In the Response Moderation layer, the generated response from the Request Moderation layer is further evaluated before being presented to the user. This evaluation includes checks for language critique coherence, language critique fluency, language critique grammar, language critique politeness y. All the checks which are there in Request Moderation layer are same with response Moderation also except for response completeness, response conciseness, response validity and response completeness wrt context.</p>
<h5 id="ResponseCompleteness">Response Completeness<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>Checks whether the response has answered all the aspects of the question specified. Response completeness score measures if the generated response has adequately answered all aspects to the question being asked. This check is important to ensure that the model is not generating incomplete responses.</p>
<h5 id="ResponseConciseness">Response Conciseness<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>Grades how concise the generated response is or if it has any other irrelevant information for the question asked. Response conciseness score measures whether the generated response holds any other information irrelevant to the question asked.</p>
<h5 id="ResponseValidity">Response Validity<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>Checks if the response generated is valid or not. A response is valid if it holds any information. In some cases, an LLM might not generate a response due to reasons like limited knowledge or the asked question not being clear. Response Validity score can be used to name these cases, where a model is not generating an informative response.</p>
<h5 id="ResponseCompletenessWrtContext">Response Completeness Wrt Context<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>Response completeness with respect to context in response moderation refers to the ability of a moderation system to accurately assess and address the content of a response based on its surrounding context. This involves understanding the nuances of the conversation, the intent of the user, and the potential impact of the response. </p>
<h4 id="ResponseComparison">Response Comparison<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>The Response Comparison element compares the generated response from the FM Moderation module with a reference response from Infosys guardrail. This comparison helps ensure consistency and evaluate the effectiveness of the moderation process.</p>
<p>The FM Moderation module ensures that the generated responses are compliant, safe, and aligned with defined guidelines. It provides granular control over the content generated by AI language models, reducing risks associated with inappropriate or harmful outputs.</p>
<h5 id="ResponsewithInfosysRAIguardrails">Response with Infosys RAI guardrails<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>Infosys RAI guardrails for response comparison likely involve a system that evaluates and compares generated responses against predefined quality standards and ethical guidelines. This process ensures that AI-generated content aligns with Infosys' values, is exact, relevant, and free from biases. By comparing responses to these guardrails, the system can name potential issues, suggest improvements, and keep a prominent level of quality and consistency in the AI outputs.</p>
<h5 id="Resultswithgpt4">Results with gpt4<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>Comparing ChatGPT-4 responses involves analyzing the quality, relevance, and coherence of its outputs across various prompts and contexts.</p>
<h3 id="Modelbasedguardrails">Model-based guardrails<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h3>
<p>Model-based guardrails we use pre-trained models trained on extensive billion-parameter datasets to effectively combat adversarial attacks. These models are equipped with sophisticated algorithms capable of discerning and mitigating malicious content by employing various metrics such as scores and thresholds. These metrics are meticulously set based on detection entities or through comparative analysis of text embeddings, ensuring robust detection and response mechanisms against adversarial threats. This approach enables our system to support ambitious standards of security and reliability, safeguarding against potential risks and ensuring the integrity of moderated content. </p>
<h4 id="RequestModeration1">Request Moderation  <a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>In the Request Moderation layer, various checks are performed on the input prompt before generating a response. These checks include Prompt Injection, Jailbreak, Privacy, Profanity, Toxicity, and Restricted Topic checks. These checks ensure that the input prompt adheres to the defined guidelines and standards.</p>
<h5 id="PromptInjectionCheck1">Prompt Injection Check<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>This check evaluates the presence of injected content in the input prompt. It calculates an injection confidence score based on the prompt and compares it against a dynamic injection threshold. The result writes down whether the check passes or fails.</p>
<h5 id="JailbreakCheck1">Jailbreak Check<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>The Jailbreak check examines the input prompt for potential attempts to manipulate or bypass the moderation system. It calculates a jailbreak similarity score and compares it against a dynamic jailbreak threshold. The result writes down whether the check passes or fails.</p>
<h5 id="PrivacyCheck">Privacy Check<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>The Privacy check allows configuration of specific entities that should be recognized and protected within the prompt, such as Aadhar numbers, passport details, or PAN numbers. It names the recognized entities and compares them against the configured entities to block. The result writes down whether the check passes or fails.</p>
<h5 id="ProfanityCheck">Profanity Check<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>The Profanity check names profane words within the input prompt. It reports the profane words named and compares them against a customized threshold. If the number of occurrences of profane words is greater than the threshold, it falls to failed category.</p>
<h5 id="ToxicityCheck">Toxicity Check<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>The Toxicity check assesses the level of toxicity in the input prompt based on metrics such as toxicity, severe toxicity, obscenity, identity attack, insult, threat, and sexual explicitness. It compares the calculated toxicity scores against a predefined toxicity threshold and at last we can assess whether response passes or fails.</p>
<h5 id="RestrictedTopicCheck">Restricted Topic Check<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>The Restricted Topic check ensures that certain predefined topics, such as explosives, terrorism, or political subjects, are not included in the input prompt. We can configure what topics needs to be restricted.</p>
<h4 id="ResponseModeration1">Response Moderation<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>In the Response Moderation layer, the generated response from the Request Moderation layer is further evaluated before being presented to the user. This evaluation includes checks for Text Quality, Text Relevance, and Refusal. All the checks which are there in Request Moderation layer are same with response Moderation also except jailbreak check and Prompt injection check since the response from the LLM may not hold these attacks. Other than it has Privacy Check, Profanity Check, Toxicity Check, Restricted Topic Check.</p>
<h5 id="PrivacyCheck1">Privacy Check<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>The Privacy check allows configuration of specific entities that should be recognized and protected within the prompt, such as Aadhar numbers, passport details, or PAN numbers. It finds the recognized entities and compares them against the configured entities to block. The result shows whether the check passes or fails.</p>
<h5 id="RestrictedTopicCheck1">Restricted Topic Check<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>The Restricted Topic check ensures that certain predefined topics, such as explosives, terrorism, or political subjects, are not included in the input prompt. We can configure what topics needs to be restricted.</p>
<h5 id="ToxicityCheck1">Toxicity Check<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>The Toxicity check assesses the level of toxicity in the input prompt based on metrics such as toxicity, severe toxicity, obscenity, identity attack, insult, threat, and sexual explicitness. It compares the calculated toxicity scores against a predefined toxicity threshold and at last we can assess whether response passes or fails.</p>
<h5 id="ProfanityCheck1">Profanity Check          <a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>              The Profanity check finds profane words within the input prompt. It reports the profane words shown and compares them against a customized threshold. If the number of occurrences of profane words is greater than the threshold, it falls to failed category.  </p>
<h5 id="textqualityTextQuality"><span class="confluence-anchor-link conf-macro output-inline" data-hasbody="false" data-local-id="e07b1ed1-62f3-4f27-8461-d5ed4a52f7b1" data-macro-id="38010849aa604ea6eb524b66255038b6ec22ef0d5a1b9ce2dfbc8562a2a5ddca" data-macro-name="anchor" id="ModerationLayer-Features-text_quality"><span class="confluence-anchor-link" id="text_quality"> </span></span>Text Quality<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>The Text Quality check assesses the readability and grade level of the generated response. Score stands for the grade level using this scale below.</p>
<div class="table-wrap dt1206052555" style="max-width: 760px; width: 100%; margin: 10px auto 0px;">
<div style="overflow-x: auto;"><table border="1" class="confluenceTable" data-layout="default" data-local-id="386f2d57-61a8-4d9d-b154-b3e05097594b" data-table-width="760" style="border-collapse: collapse; width: 100%;">
<tbody>
<tr>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p><strong>Score</strong></p></td>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p><strong>School level</strong></p></td>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p><strong>Remarks</strong></p></td>
</tr>
<tr>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>100.00-90.00</p></td>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>5th grade</p></td>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>Quite easy to read. Easily understood by an average 11-year-old student.</p></td>
</tr>
<tr>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>90.0-80.0</p></td>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>6th grade</p></td>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>Easy to read. Conversational English for consumers.</p></td>
</tr>
<tr>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>80.0-70.0</p></td>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>7th grade</p></td>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>Fairly easy to read.</p></td>
</tr>
<tr>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>70.0-60.0</p></td>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>8th &amp; 9th grade</p></td>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>Plain English. Easily understood by 13- to 15-year-old students.</p></td>
</tr>
<tr>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>60.0-50.0</p></td>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>10th to 12th grade</p></td>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>Fairly difficult to read.</p></td>
</tr>
<tr>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>50.0-30.0</p></td>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>College</p></td>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>Difficult to read.</p></td>
</tr>
<tr>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>30.0-10.0</p></td>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>College graduate</p></td>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>Exceedingly difficult to read. Best understood by university graduates.</p></td>
</tr>
<tr>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>10.0-0.0</p></td>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>Professional</p></td>
<td class="confluenceTd" style="border: 1px solid #ddd; padding: 8px; text-align: left;"><p>Extremely difficult to read. Best understood by university graduates.</p></td>
</tr>
</tbody>
</table></div>
<style>html .dt1206052555 table {min-width:532px;}</style>
</div>
<h5 id="TextRelevanceCheck">Text Relevance Check<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>The Text Relevance check measures the relevance of the generated response with respect to the input prompt.  </p>
<h5 id="RefusalCheck">Refusal Check<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>The Refusal check finds cases where the language model refuses to provide a response due to content that violates norms or guidelines.  </p>
<h4 id="AdditionalOptionalChecksaddedforRequestModerationandResponseModerationunderModelbasedGuardrails">Additional Optional Checks added for Request Moderation and Response Moderation under Model-based Guardrails<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<h5 id="InvisibleTextCheck"><strong> Invisible Text Check </strong><a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>It is a package-based evaluation check designed to detect and remove non-printable, invisible Unicode characters from text inputs.</p>
<h5 id="GibberishCheck"><strong>Gibberish Check</strong><a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>It is a model-based check designed to identify and filter out gibberish or nonsensical inputs in English language text.</p>
<h5 id="BanCodeCheck"><strong>Ban Code Check</strong><a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>It is a model-based check designed to detect code snippet in the prompt.</p>
<h5 id="SentimentCheck"><strong>Sentiment Check </strong><a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>It is a package-based check with the primary objective to gauge the sentiment of a given prompt.</p>
<h4 id="ResponseComparison1">Response Comparison<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>The Response Comparison element compares the generated response from the FM Moderation module with a reference response from Infosys guardrail. This comparison helps ensure consistency and evaluate the effectiveness of the moderation process.  </p>
<p>The FM Moderation module ensures that the generated responses are compliant, safe, and aligned with defined guidelines. It provides granular control over the content generated by AI language models, reducing risks associated with inappropriate or harmful outputs.</p>
<h5 id="ResponsewithInfosysRAIguardrails1">Response with Infosys RAI guardrails<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>Infosys RAI guardrails for response comparison likely involve a system that evaluates and compares generated responses against predefined quality standards and ethical guidelines. This process ensures that AI-generated content aligns with Infosys' values, is exact, relevant, and free from biases. By comparing responses to these guardrails, the system can find potential issues, suggest improvements, and keep a prominent level of quality and consistency in the AI outputs.</p>
<h5 id="Resultswithgpt41">Results with gpt4<a class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>Comparing ChatGPT-4 responses involves analyzing the quality, relevance, and coherence of its outputs across various prompts and contexts. </p>
<p> </p>
<p> </p>
<p> </p>
</div>
<div id="footer-comments-outlet">
<div>
<div class="page-comment-wrapper" data-testid="page-comment-wrapper">
<div class="cc-q82yp6">
<div class="_1e0c1txw _i0dl1osq _otyru2gc">
<div class="_bfhklbf8 _1bsbzwfg _4t3izwfg _2rko1ssb _19pk1b66 _2hwxutpp"></div>
<div class="_1e0c11p5 _yv0ehpgh _727q19bv _bfhk1j28 _1bsbdgin _18u0u2gc">
<div class="_nd5lzmlf _bfhklbf8 _y3gn1h6o _1yt45uws _19itglyw _2rko1l7b"></div>
<div class="_nd5lbahz _bfhklbf8 _y3gn1h6o _1yt41h4g _19itglyw _2rko1l7b"></div>
</div>
</div>
<div class="_1sb2f705 _1e0c1ule _otyrpxbi _ca0qutpp _n7zl1l7n _1bsb1osq"></div>
<div class="_1e0c1txw _1n261g80" data-testid="comment-container">
<div class="_1e0c1txw _i0dl1osq _otyru2gc">
<div class="_bfhklbf8 _1bsbzwfg _4t3izwfg _2rko1ssb _19pk1b66 _2hwxutpp"></div>
<div class="_1bsb1osq _19itglyw _2rko1l7b _4t3i1ylp _syaz9s69 _ca0qze3t _1e0c1o8l _s7n4jp4b _18u0u2gc _16jlkb7n _bfhklbf8"></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="inline-comments-outlet"></div>
</div>
</div></body><br/><br/></html>